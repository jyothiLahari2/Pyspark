{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29af164b-e548-4636-8845-e2aae77c0d70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------+\n|name  |properties                      |\n+------+--------------------------------+\n|lahari|{eyes -> black, hair -> grey}   |\n|Jyothi|{eyes -> black, hair -> blakish}|\n+------+--------------------------------+\n\nroot\n |-- name: string (nullable = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField,StructType,StringType,MapType\n",
    "data = [('lahari',{'eyes':'black','hair':'grey'}),('Jyothi',{'eyes':'black','hair':'blakish'})]\n",
    "schema = StructType([\\\n",
    "    StructField('name',StringType()),\\\n",
    "        StructField('properties',MapType(StringType(),StringType()))\n",
    "        ])\n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.show(truncate=False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a30c778-e806-4ddd-891f-04c1fbc3c40a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------+----+-------+\n|name  |properties                      |key |value  |\n+------+--------------------------------+----+-------+\n|lahari|{eyes -> black, hair -> grey}   |eyes|black  |\n|lahari|{eyes -> black, hair -> grey}   |hair|grey   |\n|Jyothi|{eyes -> black, hair -> blakish}|eyes|black  |\n|Jyothi|{eyes -> black, hair -> blakish}|hair|blakish|\n+------+--------------------------------+----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "df1 = df.select('name','properties',explode(df.properties))\n",
    "df1.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6758d162-baf9-4da9-82bd-f6cf73c0abcf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------+------------+\n|name  |properties                      |keys        |\n+------+--------------------------------+------------+\n|lahari|{eyes -> black, hair -> grey}   |[eyes, hair]|\n|Jyothi|{eyes -> black, hair -> blakish}|[eyes, hair]|\n+------+--------------------------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_keys\n",
    "\n",
    "df2 = df.withColumn('keys',map_keys(df.properties))\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "682f9761-cb8c-432e-9c89-4fea296dd9e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------+----------------+\n|name  |properties                      |values          |\n+------+--------------------------------+----------------+\n|lahari|{eyes -> black, hair -> grey}   |[black, grey]   |\n|Jyothi|{eyes -> black, hair -> blakish}|[black, blakish]|\n+------+--------------------------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_values\n",
    "df3 = df.withColumn('values',map_values(df.properties))\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3beefaf0-285c-4abd-b6a6-47eb5bc72459",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "map_keys(),map_values()&explode()",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
